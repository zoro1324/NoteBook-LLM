{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Podcast Generation Notebook\n",
                "\n",
                "This notebook demonstrates the multi-step flow for generating audio overviews from text content.\n",
                "\n",
                "**Flow:**\n",
                "1. **Generate Persona Options**: AI suggests 3 pairs of personas.\n",
                "2. **Generate Scenario Options**: AI suggests 3 scenarios based on selected personas.\n",
                "3. **Generate Podcast**: AI generates scripts and audio using the selected configuration."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "!pip install edge-tts nest_asyncio ollama"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import ollama\n",
                "import json\n",
                "import edge_tts\n",
                "import nest_asyncio\n",
                "import asyncio\n",
                "import os\n",
                "import uuid\n",
                "from IPython.display import Audio, display\n",
                "\n",
                "# Apply nest_asyncio to allow async execution in Jupyter\n",
                "nest_asyncio.apply()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Model to use\n",
                "MODEL_NAME = \"phi3:mini\"\n",
                "OUTPUT_DIR = \"./podcast_output\"\n",
                "os.makedirs(OUTPUT_DIR, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- Podcast Service Definition ---\n",
                "# Adapted from backend/generation/podcast_service.py for standalone notebook use.\n",
                "\n",
                "class PodcastService:\n",
                "    def __init__(self):\n",
                "        self.model = MODEL_NAME\n",
                "        self.voice_map = {\n",
                "            \"person1\": \"en-US-GuyNeural\",   # Male voice\n",
                "            \"person2\": \"en-US-JennyNeural\" # Female voice\n",
                "        }\n",
                "        \n",
                "    def generate_persona_options(self, text):\n",
                "        \"\"\"\n",
                "        Analyze content and propose 3 distinct persona pairs.\n",
                "        \"\"\"\n",
                "        prompt = f\"\"\"\n",
                "        Analyze the following content and propose 3 distinct pairs of personas (Host 1 and Host 2) for an audio conversation about it.\n",
                "        Each pair should represent a different dynamic or angle (e.g., Skeptic vs Believer, Expert vs Novice, Enthusiast vs Realist).\n",
                "        \n",
                "        Content Summary:\n",
                "        {text[:10000]}... (truncated)\n",
                "\n",
                "        Return ONLY a JSON object with a key 'options' which is a list of objects.\n",
                "        Each object must have 'person1' (name/role) and 'person2' (name/role).\n",
                "        Example: \n",
                "        {{\n",
                "            \"options\": [\n",
                "                {{\"person1\": \"Professor X (Expert)\", \"person2\": \"Student Y (Curious)\"}},\n",
                "                {{\"person1\": \"Tech Optimist\", \"person2\": \"Tech Skeptic\"}},\n",
                "                {{\"person1\": \"Historian\", \"person2\": \"Futurist\"}}\n",
                "            ]\n",
                "        }}\n",
                "        \"\"\"\n",
                "        try:\n",
                "            response = ollama.chat(model=self.model, messages=[{'role': 'user', 'content': prompt}], format='json')\n",
                "            data = json.loads(response['message']['content'])\n",
                "            return data.get('options', [])\n",
                "        except Exception as e:\n",
                "            print(f\"[PodcastService] Error generating persona options: {e}\")\n",
                "            return [\n",
                "                {\"person1\": \"Expert\", \"person2\": \"Novice\"},\n",
                "                {\"person1\": \"Skeptic\", \"person2\": \"Enthusiast\"},\n",
                "                {\"person1\": \"Host 1\", \"person2\": \"Host 2\"}\n",
                "            ]\n",
                "\n",
                "    def generate_scenario_options(self, text, personas=None):\n",
                "        \"\"\"\n",
                "        Generate 3 distinct conversational scenarios based on content and selected personas.\n",
                "        \"\"\"\n",
                "        persona_context = \"\"\n",
                "        if personas:\n",
                "            persona_context = f\"The conversation will be between {personas.get('person1')} and {personas.get('person2')}.\"\n",
                "\n",
                "        prompt = f\"\"\"\n",
                "        Analyze the following content and propose 3 distinct, creative conversational scenarios for an audio overview.\n",
                "        {persona_context}\n",
                "        Consider the perspectives of the specific personas defined above.\n",
                "        \n",
                "        Content Summary:\n",
                "        {text[:10000]}... (truncated)\n",
                "\n",
                "        Return ONLY a JSON object with a key 'options' which is a list of strings.\n",
                "        Example: {{\"options\": [\"Debate on ethics\", \"Deep dive into history\", \"Practical application discussion\"]}}\n",
                "        \"\"\"\n",
                "        try:\n",
                "            response = ollama.chat(model=self.model, messages=[{'role': 'user', 'content': prompt}], format='json')\n",
                "            data = json.loads(response['message']['content'])\n",
                "            return data.get('options', [])\n",
                "        except Exception as e:\n",
                "            print(f\"[PodcastService] Error generating scenario options: {e}\")\n",
                "            return [\"Deep Dive\", \"Critical Analysis\", \"Casual Overview\"]\n",
                "\n",
                "    def generate_podcast(self, text, instruction=None, person1=None, person2=None, output_dir=\"./podcast_output\"):\n",
                "        \"\"\"\n",
                "        Main method to generate an audio overview from text.\n",
                "        Returns the path to the generated audio file.\n",
                "        \"\"\"\n",
                "        # 1. Determine Roles\n",
                "        roles = self._determine_roles(text, instruction, person1, person2)\n",
                "        print(f\"[PodcastService] Selected Roles: {roles}\")\n",
                "        \n",
                "        # 2. Generate Script\n",
                "        script = self._generate_script(text, roles, instruction)\n",
                "        print(f\"[PodcastService] Generated Script with {len(script)} turns\")\n",
                "        \n",
                "        # 3. Generate Audio\n",
                "        audio_file = self._generate_audio(script, roles, output_dir)\n",
                "        \n",
                "        return audio_file\n",
                "\n",
                "    def _determine_roles(self, text, instruction=None, person1=None, person2=None):\n",
                "        \"\"\"Determine suitable roles for the conversation\"\"\"\n",
                "        \n",
                "        # If roles are explicitly provided, use them\n",
                "        if person1 and person2:\n",
                "            return {\"person1\": person1, \"person2\": person2}\n",
                "\n",
                "        instruction_context = f\"User Instruction/Theme: {instruction}\" if instruction else \"\"\n",
                "        \n",
                "        role_prompt = f\"\"\"\n",
                "        Analyze the following content and determine the two most suitable roles for a conversation about it.\n",
                "        {instruction_context}\n",
                "        \n",
                "        If the instruction suggests specific personas (e.g. \"Student and Teacher\"), USE THEM.\n",
                "        Otherwise, infer the best roles from the content.\n",
                "        \n",
                "        Examples:\n",
                "        - Instruction: \"Casual chat\" -> Person 1: \"Sarah\", Person 2: \"Naveen\"\n",
                "        - Instruction: \"Academic explanation\" -> Person 1: \"Professor\", Person 2: \"Student\"\n",
                "        - Content is Technical -> Person 1: \"Expert\", Person 2: \"Novice\"\n",
                "\n",
                "        Content:\n",
                "        {text[:10000]}... (truncated)\n",
                "\n",
                "        Return ONLY a JSON object with keys 'person1' (the lead speaker) and 'person2' (the second speaker). \n",
                "        Do not add any other text.\n",
                "        Example format: {{\"person1\": \"...\", \"person2\": \"...\"}}\n",
                "        \"\"\"\n",
                "        \n",
                "        try:\n",
                "            response = ollama.chat(model=self.model, messages=[{'role': 'user', 'content': role_prompt}], format='json')\n",
                "            roles = json.loads(response['message']['content'])\n",
                "            # Ensure keys exist\n",
                "            if 'person1' not in roles: roles['person1'] = roles.get('host', 'Speaker 1')\n",
                "            if 'person2' not in roles: roles['person2'] = roles.get('guest', 'Speaker 2')\n",
                "            return roles\n",
                "        except Exception as e:\n",
                "            print(f\"[PodcastService] Error selecting roles: {e}\")\n",
                "            return {\"person1\": \"Speaker 1\", \"person2\": \"Speaker 2\"}\n",
                "\n",
                "    def _generate_script(self, text, roles, instruction=None):\n",
                "        \"\"\"Generate the podcast script\"\"\"\n",
                "        \n",
                "        instruction_text = f\"Focus on this specific theme/format: {instruction}\" if instruction else \"Cover the key points naturally.\"\n",
                "        \n",
                "        podcast_prompt = f\"\"\"\n",
                "        Generate a natural conversation between {roles.get('person1', 'Speaker 1')} and {roles.get('person2', 'Speaker 2')} based on the following content.\n",
                "        Make it engaging, authentic, and easy to follow.\n",
                "        Make it a comprehensive deep dive. Do not limit the conversation length. \n",
                "        {instruction_text}\n",
                "\n",
                "        Content:\n",
                "        {text[:12000]}... (truncated if too long)\n",
                "\n",
                "        Return the output as a JSON object with a key 'conversation' which is a list of objects.\n",
                "        Each object in the list should have 'speaker' and 'text' keys.\n",
                "        Ensure the 'speaker' field matches exactly one of the roles: \"{roles.get('person1', 'Speaker 1')}\" or \"{roles.get('person2', 'Speaker 2')}\".\n",
                "        Example format:\n",
                "        {{\n",
                "          \"conversation\": [\n",
                "            {{\"speaker\": \"{roles.get('person1', 'Speaker 1')}\", \"text\": \"Hello...\"}},\n",
                "            {{\"speaker\": \"{roles.get('person2', 'Speaker 2')}\", \"text\": \"Hi there...\"}}\n",
                "          ]\n",
                "        }}\n",
                "        \"\"\"\n",
                "        \n",
                "        try:\n",
                "            response = ollama.chat(model=self.model, messages=[{'role': 'user', 'content': podcast_prompt}], format='json')\n",
                "            data = json.loads(response['message']['content'])\n",
                "            \n",
                "            # Extract conversation list safely\n",
                "            if 'conversation' in data:\n",
                "                return data['conversation']\n",
                "            elif isinstance(data, list):\n",
                "                return data\n",
                "            else:\n",
                "                # Try to find a list in values\n",
                "                for v in data.values():\n",
                "                    if isinstance(v, list):\n",
                "                        return v\n",
                "            return []\n",
                "            \n",
                "        except Exception as e:\n",
                "            print(f\"[PodcastService] Error generating script: {e}\")\n",
                "            return []\n",
                "\n",
                "    def _generate_audio(self, script, roles, output_dir):\n",
                "        \"\"\"Convert script to audio\"\"\"\n",
                "        if not script:\n",
                "             print(\"[PodcastService] Warning: Script is empty.\")\n",
                "             return None\n",
                "             \n",
                "        async def _generate_segment(text, voice, filename):\n",
                "            communicate = edge_tts.Communicate(text, voice)\n",
                "            await communicate.save(filename)\n",
                "\n",
                "        async def _process_script():\n",
                "            segments = []\n",
                "            person1_role = roles.get('person1', 'Speaker 1')\n",
                "            \n",
                "            for i, turn in enumerate(script):\n",
                "                speaker = turn.get('speaker', '')\n",
                "                text = turn.get('text', '')\n",
                "                \n",
                "                if not text:\n",
                "                    continue\n",
                "                \n",
                "                # Determine voice\n",
                "                # Use simple heuristics to match speaker name to role\n",
                "                if speaker == person1_role or person1_role in speaker:\n",
                "                    voice = self.voice_map['person1']\n",
                "                else:\n",
                "                    voice = self.voice_map['person2']\n",
                "                \n",
                "                filename = os.path.join(output_dir, f\"segment_{i}_{uuid.uuid4().hex[:8]}.mp3\")\n",
                "                await _generate_segment(text, voice, filename)\n",
                "                segments.append(filename)\n",
                "            \n",
                "            return segments\n",
                "\n",
                "        try:\n",
                "            # Generate all segments\n",
                "            segment_files = asyncio.run(_process_script())\n",
                "            \n",
                "            # Combine segments\n",
                "            final_filename = f\"podcast_{uuid.uuid4().hex[:8]}.mp3\"\n",
                "            final_path = os.path.join(output_dir, final_filename)\n",
                "            \n",
                "            with open(final_path, 'wb') as outfile:\n",
                "                for segment_file in segment_files:\n",
                "                    with open(segment_file, 'rb') as infile:\n",
                "                        outfile.write(infile.read())\n",
                "                    # Clean up segment\n",
                "                    try:\n",
                "                        os.remove(segment_file)\n",
                "                    except:\n",
                "                        pass\n",
                "            \n",
                "            return final_path\n",
                "            \n",
                "        except Exception as e:\n",
                "            print(f\"[PodcastService] Error generating audio: {e}\")\n",
                "            return None\n",
                "\n",
                "# Initialize Service\n",
                "service = PodcastService()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Define Content to Podcast\n",
                "document_content = \"\"\"\n",
                "Machine learning (ML) is a field of study in artificial intelligence concerned with the development and study of statistical algorithms that can learn from data and generalize to unseen data, and thus perform tasks without explicit instructions. Recently, artificial neural networks have been able to surpass many previous approaches in performance.\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 1: Generate Persona Options\n",
                "print(\"Step 1: Generating Personas...\")\n",
                "persona_options = service.generate_persona_options(document_content)\n",
                "\n",
                "print(\"\\n--- Persona Options ---\")\n",
                "for i, p in enumerate(persona_options):\n",
                "    print(f\"{i+1}. {p['person1']} vs {p['person2']}\")\n",
                "\n",
                "# Simulate User Selection (Select Option 1)\n",
                "if persona_options:\n",
                "    selected_personas = persona_options[0]\n",
                "    print(f\"\\nSelected Pair: {selected_personas['person1']} & {selected_personas['person2']}\")\n",
                "else:\n",
                "    selected_personas = {\"person1\": \"Host\", \"person2\": \"Guest\"}\n",
                "    print(\"\\nUsing default personas.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 2: Generate Scenario Options\n",
                "print(\"Step 2: Generating Scenarios...\")\n",
                "scenario_options = service.generate_scenario_options(document_content, personas=selected_personas)\n",
                "\n",
                "print(\"\\n--- Scenario Options ---\")\n",
                "for i, s in enumerate(scenario_options):\n",
                "    print(f\"{i+1}. {s}\")\n",
                "\n",
                "# Simulate User Selection (Select Option 1)\n",
                "if scenario_options:\n",
                "    selected_scenario = scenario_options[0]\n",
                "    print(f\"\\nSelected Scenario: {selected_scenario}\")\n",
                "else:\n",
                "    selected_scenario = \"General Overview\"\n",
                "    print(\"\\nUsing default scenario.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Step 3: Generate Podcast\n",
                "print(\"Step 3: Generating Podcast...\")\n",
                "audio_file = service.generate_podcast(\n",
                "    document_content,\n",
                "    instruction=selected_scenario,\n",
                "    person1=selected_personas['person1'],\n",
                "    person2=selected_personas['person2'],\n",
                "    output_dir=OUTPUT_DIR\n",
                ")\n",
                "\n",
                "if audio_file:\n",
                "    print(f\"\\n✅ Podcast Generated: {audio_file}\")\n",
                "else:\n",
                "    print(\"\\n❌ Podcast Generation Failed.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Play Audio\n",
                "if audio_file and os.path.exists(audio_file):\n",
                "    print(f\"Playing: {audio_file}\")\n",
                "    display(Audio(audio_file))\n",
                "else:\n",
                "    print(\"Audio file not found or not generated.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}